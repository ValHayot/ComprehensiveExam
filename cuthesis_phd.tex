\documentclass{report}
\usepackage{cuthesis}
\usepackage{hyperref}
\usepackage{xcolor}
\author{Valerie Hayot-Sasson}
\title{Thesis Title}
\titleOfPhDAuthor{}          % or Ms., Mrs., Miss, etc. (only for PhD's)
\PhD                            % Masters by default
\degree{Computer Science}
% \dept{Computer Science}       % default is Comp.Sci.
\cosupervisor                   % if you also have a co-supervisor

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\note}[1]{\textcolor{green}{\textit{note}: #1}}

\begin{document}
\begin{abstract}
  Text of abstract.  
\end{abstract}

\begin{acknowledgments}
  Text of acknowledgments.
\end{acknowledgments}

\chapter{Introduction}
intro here
\chapter{Parallelization frameworks}
\section{Databases}
\section{Pipelining engines}
\chapter{MapReduce}
Summary of ~\cite{mapred}

Typically simple computations need to be performed on increasingly growing large datasets. 
Processing of such large datasets require parallelization. As a result, these computations are 
complicated by details of parallelization, fault tolerance, data distribution and load balancing. The 
MapReduce library addresses this issue by allowing the expression of simple computations while 
abstracting the other details. The map and reduce paradigm was selected for this purpose as it 
was already commonly used in functional programming languages, such as Lisp, and it was 
observed that many computations could be expressed as such.

The MapReduce library operates by first dividing the data into manageable chunks (16 to 64MB). It 
then creates multiple copies of the program and distributes them across nodes. There exists a 
single master node; the remainder are worker nodes. The master node is responsible for 
delegating map and reduce tasks to the idle workers. There are two data structures found in the 
master. The first stores the state (\textit{idle}, \textit{in-progress} or \textit{completed}) of each 
\textit{map} and \textit{reduce} task, and the second stores the identity of the non-idle worker 
nodes. In contrast, the worker nodes are responsible for the execution of \textit{map} or 
\textit{reduce} tasks. A worker node assigned a \textit{map} task will parse out the key-value pairs 
from the input file and pass it to the \textit{map} function. The intermediate keys produced by the 
\textit{map} function are buffered in memory and periodically written to disk. The locations of these
intermediate files are sent to the master who is responsible for forwarding these locations to the 
reducer. A worker node assigned a \textit{reduce} task uses remote procedure calls to obtain the 
intermediate local files created by the map tasks and sorts the keys such that identical keys are 
grouped together. Each unique key and its list of values are then submitted to the the 
\textit{reduce} task and the output of the \textit{reduce} task is stored in a final output file. Once all 
\textit{reduce} tasks have completed, the master resumes the program and the 
output is returned to the user.

In order to ensure fault tolerance, the master regularly pings the worker nodes. Should a worker 
node not respond after a certain delay, the master labels the worker as failed. The \textit{map} 
tasks that were completed by the worker are all returned to their original state (\textit{idle}) as 
\textit{map} task data is stored locally. Both the completed and in-progress worker's 
\textit{map} tasks are subsequently reassigned to other workers. Only the failed worker's \textit{in-
progress} \textit{reduce} tasks need to be reassigned.

The master node undergoes periodic checkpoints, such that the master node can be reinitialized 
from its last checkpoint in case of failure. Master node failure is, however, unlikely.

As network bandwidth is a scarce resource, the master attempts to schedule \textit{map} tasks 
closest to where the data is located. it will first attempt to schedule a map task on the host that 
contains the data; should that option not be available, the master the will attempts to 
schedule the \textit{map} task on a host nearest to the data (e.g. same network switch)

Ideally, the number of \textit{map} and \textit{reduce} tasks should be much larger than the number 
of available worker nodes. Having it as such improves both dynamic load balancing and recovery 
time. The number of \textit{map} tasks used in practice typically corresponds to the 
size of the input chunks, whereas the number of \textit{reduce} tasks are a small multiple of the 
number of worker nodes used.

When nearing completion of the MapReduce program, it is possible for  ``stragglers" (\textit{in-
progress} tasks running on nodes with below average performance) to delay completion. As a 
measure to counteract this, the master node assigns the same task to idle workers. The task is 
then marked as completed as soon as either the primary or the backups complete the task. 
This strategy has been found to significantly improve performance when used with very large 
datasets. \note{44\% speedup with their sort program}.

A few extensions have also been added to the library in order to improve user experience. An 
important extension is the introduction of a \textit{combiner}, which enables the commutative and 
associative reduce function to be applied to the same keys on the hosts where the \textit{map} task 
was executed. Like the \textit{map} task, the \textit{combiner} produces intermediate output which 
is sent to the \textit{reducer}. This alleviates the amount of key-value pairs that must be transferred 
over the network from the map host to the reduce host, and as a result, improves performance. 
Other extensions include the ability to create user-defined partitioning functions, a guaranteed 
increasing key sort order, the ability for the user to specify input types, an option to skip records 
that continuously result in execution failure, the ability to produce auxiliary output files in 
\textit{map} or \textit{reduce} task, live status updates stream to HTTP server,  the ability to run all 
code on a single local machine, and a \textit{Counter} class.

\note{Brief hadoop section??}

\section{Hadoop Distributed File System}
Summary of \cite{hadoop}

The Hadoop Distributed File System (HDFS) is the filesystem component of Hadoop. The 
metadata in HDFS is stored in on a dedicated server known as the NameNode, whereas 
application data is distributed across many servers referred to as DataNode. To ensure fault 
tolerance, HDFS replicates the data across multiple DataNodes (default replication factor: 
3). Not only does this ensure that the data is not lost in the event of node failure, but it also increases data transfer bandwidth, as the data can be accessed from multiple nodes, and thus, there are more opportunities for computations to be performed nearest to where the data is located. 

The NameNode contains the namespace tree, a hierarchy of directories and their files, as well as the mapping of the split file blocks to DataNodes. The entire namespace is stored in memory. Information on the directories and files, such as modification and access times, namespace and disk quotes, are stored within \textit{inodes} on the NameNode. The name system's metadata, \textit{inode} and file block mapping, is known as the \textit{image}. Persistent record of the image that is stored on the local file system are known as \textit{checkpoint}. Locations of block replicas are not stored in the checkpoint as they may change over time. The \textit{journal} is a log of the modifications made to the image. Both the checkpoint and the journal may be copied across servers for increased durability. The journal is played back during the NameNode restart in order to restore the cluster.

When a client requests to read data, it must first contact the NameNode. The NameNode provides it with the replica locations, and the client reads from the DataNode located closest to it. When the client requests to write a file, it contacts the NameNode which selects the DataNodes that will host the replicas. The client subsequently writes the data directly to the DataNodes in a pipeline fashion (The data gets propagated through each DataNode by being transferred from the nearest DataNode to it).

There is only one NameNode assigned to each cluster, however, each cluster can have multiple clients and execute multiple tasks concurrently.


A block replica stored on a DataNode consists of two files stored on the local file system: the metadata and the data. 

The DataNode connects to the NameNode during startup and performs handshake to for DataNode namespace ID and software version verification. Should either namespace ID or software version not match those of the NameNode, the DataNode shuts down.

To ensure integrity of the system, a \textit{namespace ID} is assigned to all nodes during formatting of the namespace. DataNodes with different namespace IDs to the NameNode will not be permitted to join the cluster. Should the DataNode have not been assigned a namespace ID, it will be permitted to join the cluster. The cluster's namespace ID will then be assigned to that DataNode.


Following the handshake, the DataNode register with the NameNode using their storage ID. The storage ID is a unique ID generated after initial registration to the NameNode and that is persistently stored on the DataNode. It permits identification of the DataNode in the event of an IP address or port change. 


 




inodes, stored on namenode, represent file and directories. inodes record attributes such as permissions, modifications and access times, namespace and disk quotas.

namenode keeps track of namespace tree and mapping of file blocks to datanodes.

The \textit{image} stores the \textit{inode} data and the list of blocks belonging to each file.

The \textit{checkpoint} is a persistent record of the \textit{image} stored in the local filesystem.

The \textit{journal} is the modification log stored on the local filesystem.

\section{Apache Spark}
\cite{spark}
\chapter{MapReduce applications in neuroscience}
\cite{thunder}

\section{Schedulers}
\chapter{Pipelining engines used in neuroscience}
\cite{nipype}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Body of Thesis goes here.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{bibliography}
\bibliographystyle{ieeetr}
%\bibliography{abbr,chalin,common,larch,tn}  %place your .bib files here
%\bibliographystyle{alpha}                   %the bibliography style to use

\end{document}
